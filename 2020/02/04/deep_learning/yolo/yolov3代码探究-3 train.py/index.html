<!DOCTYPE html>
<html >
    <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1, initial-scale=1, maximum-scale=5, viewport-fit=cover">
    <title>Hexo</title>
    <meta name="description" content="yolov3代码探究-3 train.pygithub-yolov3train.py 1234567891011121314151617181920212223242526272829303132333435363738# https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov3&#x2F;blob&#x2F;master&#x2F;train.pyimport argparseimport timeimpo">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/2020/02/04/deep_learning/yolo/yolov3%E4%BB%A3%E7%A0%81%E6%8E%A2%E7%A9%B6-3%20train.py/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="yolov3代码探究-3 train.pygithub-yolov3train.py 1234567891011121314151617181920212223242526272829303132333435363738# https:&#x2F;&#x2F;github.com&#x2F;ultralytics&#x2F;yolov3&#x2F;blob&#x2F;master&#x2F;train.pyimport argparseimport timeimpo">
<meta property="og:locale">
<meta property="article:published_time" content="2020-02-04T05:26:23.000Z">
<meta property="article:modified_time" content="2020-02-04T05:26:23.000Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">

    
    <link rel="icon" href="https://i.loli.net/2021/03/04/Y8OtTdUnM4isHxh.jpg" type="image/x-icon">

    
<link rel="stylesheet" href="/css/common.min.css">



    
    
    
    
        <link href="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/css/lightgallery.min.css" rel="stylesheet">
    
    
    
<link rel="stylesheet" href="/css/iconfont.min.css">

    
<meta name="generator" content="Hexo 5.4.0"></head>

    <body>
        <header class="header header-fixture">
    <div class="profile-search-wrap flex sm:block">
        
        
        <div class="profile sm:text-center md:px-1 lg:px-3 sm:pb-4 sm:pt-6">
            <a id="avatar" role="link" href="https://github.com/grace-gu" class="inline-block lg:w-16 lg:h-16 w-8 h-8 m-2" target="_blank" rel="noopener" rel="noreferrer" >
                <img src="https://i.loli.net/2021/03/04/Y8OtTdUnM4isHxh.jpg" class="rounded-full" alt="avatar">
            </a>
            <h2 id="name" class="hidden lg:block">Grace</h2>
            <h3 id="title" class="hidden xl:block">coder</h3>
            
            <small id="location" class="hidden lg:block">
                <i class="iconfont icon-map-icon"></i>
                Beijing, China
            </small>
            
        </div>
        
        
<div class="search flex-1 flex lg:inline-block sm:hidden lg:px-4 lg:mt-2 lg:mb-4 lg:w-full">
    <form id="search-form" class="my-auto flex-1 lg:border lg:border-solid lg:border-gray-200">
        <div class="input-group table bg-gray-100 lg:bg-white w-full">
            <input id="search-input" type="text" placeholder="Search" class="inline-block w-full bg-gray-100 lg:bg-white">
            <span class="table-cell">
                <button name="search tigger button" disabled>
                    <i class="iconfont icon-search m-2"></i>
                </button>
            </span>
        </div>
    </form>
        
<script id="search-teamplate" type="text/html" data-path="/content.json">
    <div>
        <div class="search-header bg-gray-400">
            <input id="actual-search-input" model="keyword" ref="input" class="inline-block w-full h-10 px-2 py-1" placeholder="Search" type="text">
        </div>
        <div class="search-result bg-gray-200">
            {{#each searchPosts}}
            <a href="/{{ path }}" class="result-item block px-2 pb-3 mb-1 pt-1 hover:bg-indigo-100">
                <i class="iconfont icon-file"></i>
                <h1 class="result-title inline font-medium text-lg">{{ title }}</h1>
                <p class="result-content text-gray-600 text-sm">{{{ text }}}</p>
            </a>
            {{/each}}
        </div>
    </div>
</script>

</div>


        <button name="menu toogle button" id="menu-toggle-btn" class="block sm:hidden p-3" role="button" aria-expanded="false">
            <i class="iconfont icon-hamburger"></i>
        </button>
    </div>
    <nav id="menu-nav" class="hidden sm:flex flex-col">
        
        
            <div class="menu-item menu-home" role="menuitem">
                <a href="/.">
                    <i class="iconfont icon-home" aria-hidden="true"></i>
                    <span class="menu-title">Home</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-archives" role="menuitem">
                <a href="/archives">
                    <i class="iconfont icon-archive" aria-hidden="true"></i>
                    <span class="menu-title">Archives</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-categories" role="menuitem">
                <a href="/categories">
                    <i class="iconfont icon-folder" aria-hidden="true"></i>
                    <span class="menu-title">Categories</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-tags" role="menuitem">
                <a href="/tags">
                    <i class="iconfont icon-tag" aria-hidden="true"></i>
                    <span class="menu-title">Tags</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-repository" role="menuitem">
                <a href="/repository">
                    <i class="iconfont icon-project" aria-hidden="true"></i>
                    <span class="menu-title">Repository</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-links" role="menuitem">
                <a href="/links">
                    <i class="iconfont icon-friend" aria-hidden="true"></i>
                    <span class="menu-title">Links</span>
                </a>
            </div>
        
        
            <div class="menu-item menu-about" role="menuitem">
                <a href="/about">
                    <i class="iconfont icon-cup" aria-hidden="true"></i>
                    <span class="menu-title">About</span>
                </a>
            </div>
        
        
<div class="social-links flex sm:flex-col lg:hidden mt-5">
    
        <span class="social-item text-center">
            <a target="_blank" rel="noopener" href="https://github.com/grac-gu">
                <i class="iconfont social-icon icon-github"></i>
                <span class="menu-title hidden lg:inline">menu.github</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/None">
                <i class="iconfont social-icon icon-telegram"></i>
                <span class="menu-title hidden lg:inline">menu.telegram</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/None">
                <i class="iconfont social-icon icon-twitter"></i>
                <span class="menu-title hidden lg:inline">menu.twitter</span>
            </a>
        </span>
    
        <span class="social-item text-center">
            <a href="/atom.xml">
                <i class="iconfont social-icon icon-rss"></i>
                <span class="menu-title hidden lg:inline">menu.rss</span>
            </a>
        </span>
    
</div>


    </nav>
</header>

        <section class="main-section">
            
    <main class="flex-1 px-4 py-12 md:px-5 lg:px-8 lg:py-4 relative min-h-screen">
    

    <article class="content article article-archives article-type-list" itemscope="">
        <header class="article-header">
            


            <p class="article-meta mb-3 text-xs">
                <span class="article-date">
    <i class="iconfont icon-calendar-check"></i>
	<a href="/2020/02/04/deep_learning/yolo/yolov3%E4%BB%A3%E7%A0%81%E6%8E%A2%E7%A9%B6-3%20train.py/" class="article-date">
	  <time datetime="2020-02-04T05:26:23.000Z" itemprop="datePublished">Feb 4</time>
	</a>
</span>

                

                

                <span class="_partial/post-comment"><i class="icon icon-comment"></i>
                    <a href="/2020/02/04/deep_learning/yolo/yolov3%E4%BB%A3%E7%A0%81%E6%8E%A2%E7%A9%B6-3%20train.py/#comments" class="article-comment-link">
                        Comments
                    </a>
                </span>
                

            </p>
        </header>
        <div class="marked-body article-body">
            <h1 id="yolov3代码探究-3-train-py"><a href="#yolov3代码探究-3-train-py" class="headerlink" title="yolov3代码探究-3 train.py"></a>yolov3代码探究-3 train.py</h1><p><a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov3">github-yolov3</a><br><a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov3/blob/master/train.py">train.py</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># https://github.com/ultralytics/yolov3/blob/master/train.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.optim.lr_scheduler <span class="keyword">as</span> lr_scheduler</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> test  <span class="comment"># import test.py to get mAP after each epoch</span></span><br><span class="line"><span class="keyword">from</span> models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> utils.datasets <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> utils.utils <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment">#      0.109      0.297       0.15      0.126       7.04      1.666      4.062     0.1845       42.6       3.34      12.61      8.338     0.2705      0.001         -4        0.9     0.0005   320 giou + best_anchor False</span></span><br><span class="line"><span class="comment">#      0.223      0.218      0.138      0.189       9.28      1.153      4.376    0.08263      24.28       3.05      20.93      2.842     0.2759   0.001357     -5.036     0.9158  0.0005722   mAP/F1 - 50/50 weighting</span></span><br><span class="line"><span class="comment">#      0.231      0.215      0.135      0.191       9.51      1.432      3.007    0.06082      24.87      3.477      24.13      2.802     0.3436   0.001127     -5.036     0.9232  0.0005874</span></span><br><span class="line"><span class="comment">#      0.246      0.194      0.128      0.192       8.12      1.101      3.954     0.0817      22.83      3.967      19.83      1.779     0.3352   0.000895     -5.036     0.9238  0.0007973</span></span><br><span class="line"><span class="comment"># 0.242	0.296	0.196	0.231	5.67	0.8541	4.286	0.1539	21.61	1.957	22.9	2.894	0.3689	0.001844	-4	0.913	0.000467</span></span><br><span class="line"><span class="comment"># 0.298	0.244	0.167	0.247	4.99	0.8896	4.067	0.1694	21.41	2.033	25.61	1.783	0.4115	0.00128	    -4	0.950	0.000377</span></span><br><span class="line"><span class="comment"># 0.268	0.268	0.178	0.240	4.36	1.104	5.596	0.2087	14.47	2.599	16.27	2.406	0.4114	0.001585	-4	0.950	0.000524</span></span><br><span class="line"><span class="comment"># 0.161	0.327	0.190	0.193	7.82	1.153	4.062	0.1845	24.28	3.05	20.93	2.842	0.2759	0.001357	-4	0.916	0.000572  # 320 --epochs 2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Training hyperparameters</span></span><br><span class="line">hyp = &#123;<span class="string">&#x27;giou&#x27;</span>: <span class="number">0.8541</span>,  <span class="comment"># giou loss gain</span></span><br><span class="line">       <span class="string">&#x27;xy&#x27;</span>: <span class="number">4.062</span>,  <span class="comment"># xy loss gain</span></span><br><span class="line">       <span class="string">&#x27;wh&#x27;</span>: <span class="number">0.1845</span>,  <span class="comment"># wh loss gain</span></span><br><span class="line">       <span class="string">&#x27;cls&#x27;</span>: <span class="number">21.61</span>,  <span class="comment"># cls loss gain</span></span><br><span class="line">       <span class="string">&#x27;cls_pw&#x27;</span>: <span class="number">1.957</span>,  <span class="comment"># cls BCELoss positive_weight</span></span><br><span class="line">       <span class="string">&#x27;obj&#x27;</span>: <span class="number">22.9</span>,  <span class="comment"># obj loss gain</span></span><br><span class="line">       <span class="string">&#x27;obj_pw&#x27;</span>: <span class="number">2.894</span>,  <span class="comment"># obj BCELoss positive_weight</span></span><br><span class="line">       <span class="string">&#x27;iou_t&#x27;</span>: <span class="number">0.3689</span>,  <span class="comment"># iou target-anchor training threshold</span></span><br><span class="line">       <span class="string">&#x27;lr0&#x27;</span>: <span class="number">0.001844</span>,  <span class="comment"># initial learning rate</span></span><br><span class="line">       <span class="string">&#x27;lrf&#x27;</span>: -<span class="number">4.</span>,  <span class="comment"># final learning rate = lr0 * (10 ** lrf)</span></span><br><span class="line">       <span class="string">&#x27;momentum&#x27;</span>: <span class="number">0.913</span>,  <span class="comment"># SGD momentum</span></span><br><span class="line">       <span class="string">&#x27;weight_decay&#x27;</span>: <span class="number">0.000467</span>&#125;  <span class="comment"># optimizer weight decay</span></span><br></pre></td></tr></table></figure>
<p>&nbsp;<br><strong>含金量超高的一个环节来了！</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">cfg,</span></span></span><br><span class="line"><span class="function"><span class="params">          data_cfg,</span></span></span><br><span class="line"><span class="function"><span class="params">          img_size=<span class="number">416</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          epochs=<span class="number">100</span>,  <span class="comment"># 500200 batches at bs 16, 117263 images = 273 epochs</span></span></span></span><br><span class="line"><span class="function"><span class="params">          batch_size=<span class="number">16</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">          accumulate=<span class="number">4</span></span>):</span>  <span class="comment"># effective bs = batch_size * accumulate = 8 * 8 = 64</span></span><br><span class="line">    <span class="comment"># Initialize</span></span><br><span class="line">    init_seeds()</span><br><span class="line">    weights = <span class="string">&#x27;weights&#x27;</span> + os.sep</span><br><span class="line">    last = weights + <span class="string">&#x27;last.pt&#x27;</span></span><br><span class="line">    best = weights + <span class="string">&#x27;best.pt&#x27;</span></span><br><span class="line">    device = torch_utils.select_device()</span><br><span class="line">    multi_scale = opt.multi_scale</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> multi_scale:</span><br><span class="line">        img_size_min = <span class="built_in">round</span>(img_size / <span class="number">32</span> / <span class="number">1.5</span>)</span><br><span class="line">        img_size_max = <span class="built_in">round</span>(img_size / <span class="number">32</span> * <span class="number">1.5</span>)</span><br><span class="line">        img_size = img_size_max * <span class="number">32</span>  <span class="comment"># initiate with maximum multi_scale size</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Configure run</span></span><br><span class="line">    data_dict = parse_data_cfg(data_cfg)</span><br><span class="line">    train_path = data_dict[<span class="string">&#x27;train&#x27;</span>]</span><br><span class="line">    nc = <span class="built_in">int</span>(data_dict[<span class="string">&#x27;classes&#x27;</span>])  <span class="comment"># number of classes</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize model</span></span><br><span class="line">    model = Darknet(cfg).to(device)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Optimizer</span></span><br><span class="line">    optimizer = optim.SGD(model.parameters(), lr=hyp[<span class="string">&#x27;lr0&#x27;</span>], momentum=hyp[<span class="string">&#x27;momentum&#x27;</span>], weight_decay=hyp[<span class="string">&#x27;weight_decay&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    cutoff = -<span class="number">1</span>  <span class="comment"># backbone reaches to cutoff layer</span></span><br><span class="line">    start_epoch = <span class="number">0</span></span><br><span class="line">    best_fitness = <span class="number">0.0</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    这边的代码学习意义很大。具体包括：</span></span><br><span class="line"><span class="string">    1. 如何迁移学习</span></span><br><span class="line"><span class="string">    2. 如何在上一次训练的基础上继续训练</span></span><br><span class="line"><span class="string">    3. 如何保存训练的中间结果</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 迁移学习或者加载之前训练成果的代码 </span></span><br><span class="line">    <span class="keyword">if</span> opt.resume <span class="keyword">or</span> opt.transfer:  <span class="comment"># Load previously saved model</span></span><br><span class="line">        <span class="comment"># 迁移学习</span></span><br><span class="line">        <span class="keyword">if</span> opt.transfer:  <span class="comment"># Transfer learning</span></span><br><span class="line">						<span class="comment"># 获得yolo_layer的size</span></span><br><span class="line">            nf = <span class="built_in">int</span>(model.module_defs[model.yolo_layers[<span class="number">0</span>] - <span class="number">1</span>][<span class="string">&#x27;filters&#x27;</span>])  <span class="comment"># yolo layer size (i.e. 255)</span></span><br><span class="line">            <span class="comment"># torch.load加载预训练好的模型，weights是文件夹路径, map_location可以根据情况选择加载到GPU还是CPU.  device = torch_utils.select_device()</span></span><br><span class="line">            chkpt = torch.load(weights + <span class="string">&#x27;yolov3-spp.pt&#x27;</span>, map_location=device)</span><br><span class="line">            <span class="comment"># k指层的名字name，v指权重/参数param。如果有权重且v不是yolo层的前一层，那就加载权重到model, strict，默认是True，表示预训练模型的层和自己定义的网络结构层严格对应相等（比如层名和维度）</span></span><br><span class="line">            model.load_state_dict(&#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> chkpt[<span class="string">&#x27;model&#x27;</span>].items() <span class="keyword">if</span> v.numel() &gt; <span class="number">1</span> <span class="keyword">and</span> v.shape[<span class="number">0</span>] != <span class="number">255</span>&#125;,</span><br><span class="line">                                  strict=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 对model中的每层的参数，注意！不是每个参数</span></span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters():</span><br><span class="line">                <span class="comment">#requires_grad表示是否进行梯度更新。只有yolo层的前一层需要</span></span><br><span class="line">                p.requires_grad = <span class="literal">True</span> <span class="keyword">if</span> p.shape[<span class="number">0</span>] == nf <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># resume from last.pt</span></span><br><span class="line">            <span class="keyword">if</span> opt.bucket:</span><br><span class="line">                os.system(<span class="string">&#x27;gsutil cp gs://%s/last.pt %s&#x27;</span> % (opt.bucket, last))  <span class="comment"># download from bucket</span></span><br><span class="line">            chkpt = torch.load(last, map_location=device)  <span class="comment"># load checkpoint</span></span><br><span class="line">            model.load_state_dict(chkpt[<span class="string">&#x27;model&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 除了要加载checkpoint中的模型，优化函数的参数可能也随着训练改变了，因此还需要加载优化函数的参数</span></span><br><span class="line">        <span class="keyword">if</span> chkpt[<span class="string">&#x27;optimizer&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            optimizer.load_state_dict(chkpt[<span class="string">&#x27;optimizer&#x27;</span>])</span><br><span class="line">            best_fitness = chkpt[<span class="string">&#x27;best_fitness&#x27;</span>]</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 作者还设置了一个training_results用来保存之前的训练结果</span></span><br><span class="line">        <span class="keyword">if</span> chkpt[<span class="string">&#x27;training_results&#x27;</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;results.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                file.write(chkpt[<span class="string">&#x27;training_results&#x27;</span>])  <span class="comment"># write results.txt</span></span><br><span class="line"></span><br><span class="line">        start_epoch = chkpt[<span class="string">&#x27;epoch&#x27;</span>] + <span class="number">1</span></span><br><span class="line">        <span class="keyword">del</span> chkpt</span><br><span class="line"></span><br><span class="line">    <span class="comment">#既不迁移学习也不加载过去的训练模型</span></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># Initialize model with backbone (optional)</span></span><br><span class="line">        <span class="comment">#load_darknet_weights是作者写的函数，用来加载权重</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;-tiny.cfg&#x27;</span> <span class="keyword">in</span> cfg:</span><br><span class="line">            cutoff = load_darknet_weights(model, weights + <span class="string">&#x27;yolov3-tiny.conv.15&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cutoff = load_darknet_weights(model, weights + <span class="string">&#x27;darknet53.conv.74&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Remove old results</span></span><br><span class="line">        <span class="comment"># glob.glob相加只是单纯的罗列所有文件，把所有过去的结果都删除</span></span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> glob.glob(<span class="string">&#x27;*_batch*.jpg&#x27;</span>) + glob.glob(<span class="string">&#x27;results.txt&#x27;</span>):</span><br><span class="line">            os.remove(f)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Scheduler https://github.com/ultralytics/yolov3/issues/238</span></span><br><span class="line">    <span class="comment"># lf = lambda x: 1 - x / epochs  # linear ramp to zero</span></span><br><span class="line">    <span class="comment"># lf = lambda x: 10 ** (hyp[&#x27;lrf&#x27;] * x / epochs)  # exp ramp</span></span><br><span class="line">    <span class="comment"># lf = lambda x: 1 - 10 ** (hyp[&#x27;lrf&#x27;] * (1 - x / epochs))  # inverse exp ramp</span></span><br><span class="line">    <span class="comment"># scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)</span></span><br><span class="line">    <span class="comment">#一个调整学习率的策略，milestones表示多少次变一次学习率</span></span><br><span class="line">    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[<span class="built_in">round</span>(opt.epochs * x) <span class="keyword">for</span> x <span class="keyword">in</span> (<span class="number">0.8</span>, <span class="number">0.9</span>)], gamma=<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment">#设置初始时的学习率</span></span><br><span class="line">    scheduler.last_epoch = start_epoch - <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># # Plot lr schedule</span></span><br><span class="line">    <span class="comment"># y = []</span></span><br><span class="line">    <span class="comment"># for _ in range(epochs):</span></span><br><span class="line">    <span class="comment">#     scheduler.step()</span></span><br><span class="line">    <span class="comment">#     y.append(optimizer.param_groups[0][&#x27;lr&#x27;])</span></span><br><span class="line">    <span class="comment"># plt.plot(y, label=&#x27;LambdaLR&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.xlabel(&#x27;epoch&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.ylabel(&#x27;LR&#x27;)</span></span><br><span class="line">    <span class="comment"># plt.tight_layout()</span></span><br><span class="line">    <span class="comment"># plt.savefig(&#x27;LR.png&#x27;, dpi=300)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dataset</span></span><br><span class="line">    <span class="comment"># 加载数据集 </span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27; </span></span><br><span class="line"><span class="string">    LoadImagesAndLabels是作者写的读取数据的类</span></span><br><span class="line"><span class="string">    getitem返回的包括：</span></span><br><span class="line"><span class="string">      img, labels, img_path, (h,w) </span></span><br><span class="line"><span class="string">      其中labels:image_id, class, x, y, w, h, 表示位置的大小都是0-1 </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    dataset = LoadImagesAndLabels(train_path,</span><br><span class="line">                                  img_size,</span><br><span class="line">                                  batch_size,</span><br><span class="line">                                  augment=<span class="literal">True</span>,</span><br><span class="line">                                  rect=opt.rect)  <span class="comment"># rectangular training</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Initialize distributed training</span></span><br><span class="line">    <span class="comment"># 分布式训练, 我实际使用的是需要改代码的，有张显卡不能用所以要限制其使用的显卡</span></span><br><span class="line">    <span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">        dist.init_process_group(backend=<span class="string">&#x27;nccl&#x27;</span>,  <span class="comment"># &#x27;distributed backend&#x27;</span></span><br><span class="line">                                init_method=<span class="string">&#x27;tcp://127.0.0.1:9999&#x27;</span>,  <span class="comment"># distributed training init method</span></span><br><span class="line">                                world_size=<span class="number">1</span>,  <span class="comment"># number of nodes for distributed training</span></span><br><span class="line">                                rank=<span class="number">0</span>)  <span class="comment"># distributed training node rank</span></span><br><span class="line"></span><br><span class="line">        model = torch.nn.parallel.DistributedDataParallel(model)</span><br><span class="line">        <span class="comment"># sampler = torch.utils.data.distributed.DistributedSampler(dataset)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Dataloader</span></span><br><span class="line">    dataloader = DataLoader(dataset,</span><br><span class="line">                            batch_size=batch_size,</span><br><span class="line">                            num_workers=opt.num_workers,</span><br><span class="line">                            shuffle=<span class="keyword">not</span> opt.rect,  <span class="comment"># Shuffle=True unless rectangular training is used</span></span><br><span class="line">                            pin_memory=<span class="literal">True</span>,</span><br><span class="line">                            collate_fn=dataset.collate_fn)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Mixed precision training https://github.com/NVIDIA/apex</span></span><br><span class="line">    mixed_precision = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> mixed_precision:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">from</span> apex <span class="keyword">import</span> amp</span><br><span class="line">            model, optimizer = amp.initialize(model, optimizer, opt_level=<span class="string">&#x27;O1&#x27;</span>, verbosity=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">except</span>:  <span class="comment"># not installed: install help: https://github.com/NVIDIA/apex/issues/259</span></span><br><span class="line">            mixed_precision = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Start training</span></span><br><span class="line">    model.hyp = hyp  <span class="comment"># attach hyperparameters to model</span></span><br><span class="line">    <span class="comment"># model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device)  # attach class weights</span></span><br><span class="line">    model_info(model, report=<span class="string">&#x27;summary&#x27;</span>)  <span class="comment"># &#x27;full&#x27; or &#x27;summary&#x27;</span></span><br><span class="line">    nb = <span class="built_in">len</span>(dataloader)</span><br><span class="line">    maps = np.zeros(nc)  <span class="comment"># mAP per class</span></span><br><span class="line">    results = (<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)  <span class="comment"># P, R, mAP, F1, test_loss</span></span><br><span class="line">    n_burnin = <span class="built_in">min</span>(<span class="built_in">round</span>(nb / <span class="number">5</span> + <span class="number">1</span>), <span class="number">1000</span>)  <span class="comment"># burn-in batches</span></span><br><span class="line">    t, t0 = time.time(), time.time()</span><br><span class="line">    torch.cuda.empty_cache()</span><br><span class="line">    <span class="comment"># 训练过程</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(start_epoch, epochs):</span><br><span class="line">        <span class="comment"># 将model.training设置成true</span></span><br><span class="line">        model.train()</span><br><span class="line">        print((<span class="string">&#x27;\n%8s%12s&#x27;</span> + <span class="string">&#x27;%10s&#x27;</span> * <span class="number">7</span>) %</span><br><span class="line">              (<span class="string">&#x27;Epoch&#x27;</span>, <span class="string">&#x27;Batch&#x27;</span>, <span class="string">&#x27;GIoU/xy&#x27;</span>, <span class="string">&#x27;wh&#x27;</span>, <span class="string">&#x27;obj&#x27;</span>, <span class="string">&#x27;cls&#x27;</span>, <span class="string">&#x27;total&#x27;</span>, <span class="string">&#x27;targets&#x27;</span>, <span class="string">&#x27;img_size&#x27;</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update scheduler</span></span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Freeze backbone at epoch 0, unfreeze at epoch 1 (optional)</span></span><br><span class="line">        freeze_backbone = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">if</span> freeze_backbone <span class="keyword">and</span> epoch &lt; <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">for</span> name, p <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">                <span class="keyword">if</span> <span class="built_in">int</span>(name.split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">1</span>]) &lt; cutoff:  <span class="comment"># if layer &lt; 75</span></span><br><span class="line">                    p.requires_grad = <span class="literal">False</span> <span class="keyword">if</span> epoch == <span class="number">0</span> <span class="keyword">else</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># # Update image weights (optional)</span></span><br><span class="line">        <span class="comment"># w = model.class_weights.cpu().numpy() * (1 - maps)  # class weights</span></span><br><span class="line">        <span class="comment"># image_weights = labels_to_image_weights(dataset.labels, nc=nc, class_weights=w)</span></span><br><span class="line">        <span class="comment"># dataset.indices = random.choices(range(dataset.n), weights=image_weights, k=dataset.n)  # random weighted index</span></span><br><span class="line"></span><br><span class="line">        mloss = torch.zeros(<span class="number">5</span>).to(device)  <span class="comment"># mean losses</span></span><br><span class="line">        pbar = tqdm(<span class="built_in">enumerate</span>(dataloader), total=nb)  <span class="comment"># progress bar</span></span><br><span class="line">        <span class="keyword">for</span> i, (imgs, targets, paths, _) <span class="keyword">in</span> pbar:</span><br><span class="line">            imgs = imgs.to(device)</span><br><span class="line">            targets = targets.to(device)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Multi-Scale training <span class="doctag">TODO:</span> short-side to 32-multiple https://github.com/ultralytics/yolov3/issues/358</span></span><br><span class="line">            <span class="keyword">if</span> multi_scale:</span><br><span class="line">                <span class="keyword">if</span> (i + nb * epoch) / accumulate % <span class="number">10</span> == <span class="number">0</span>:  <span class="comment">#  adjust (67% - 150%) every 10 batches</span></span><br><span class="line">                    img_size = random.choice(<span class="built_in">range</span>(img_size_min, img_size_max + <span class="number">1</span>)) * <span class="number">32</span></span><br><span class="line">                    <span class="comment"># print(&#x27;img_size = %g&#x27; % img_size)</span></span><br><span class="line">                scale_factor = img_size / <span class="built_in">max</span>(imgs.shape[-<span class="number">2</span>:])</span><br><span class="line">                imgs = F.interpolate(imgs, scale_factor=scale_factor, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Plot images with bounding boxes</span></span><br><span class="line">            <span class="keyword">if</span> epoch == <span class="number">0</span> <span class="keyword">and</span> i == <span class="number">0</span>:</span><br><span class="line">                plot_images(imgs=imgs, targets=targets, paths=paths, fname=<span class="string">&#x27;train_batch%g.jpg&#x27;</span> % i)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># SGD burn-in</span></span><br><span class="line">            <span class="keyword">if</span> epoch == <span class="number">0</span> <span class="keyword">and</span> i &lt;= n_burnin:</span><br><span class="line">                lr = hyp[<span class="string">&#x27;lr0&#x27;</span>] * (i / n_burnin) ** <span class="number">4</span></span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">                    x[<span class="string">&#x27;lr&#x27;</span>] = lr</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Run model</span></span><br><span class="line">            pred = model(imgs)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute loss</span></span><br><span class="line">            <span class="comment"># compute_loss是作者自己写的，是重点章节，哎哟真不容易，总算到重点章节了</span></span><br><span class="line">            loss, loss_items = compute_loss(pred, targets, model, giou_loss=<span class="keyword">not</span> opt.xywh)</span><br><span class="line">            <span class="keyword">if</span> torch.isnan(loss):</span><br><span class="line">                print(<span class="string">&#x27;WARNING: nan loss detected, ending training&#x27;</span>)</span><br><span class="line">                <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Compute gradient</span></span><br><span class="line">            <span class="keyword">if</span> mixed_precision:</span><br><span class="line">                <span class="keyword">with</span> amp.scale_loss(loss, optimizer) <span class="keyword">as</span> scaled_loss:</span><br><span class="line">                    scaled_loss.backward()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss.backward()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Accumulate gradient for x batches before optimizing</span></span><br><span class="line">            <span class="keyword">if</span> (i + <span class="number">1</span>) % accumulate == <span class="number">0</span> <span class="keyword">or</span> (i + <span class="number">1</span>) == nb:</span><br><span class="line">                optimizer.step()</span><br><span class="line">                optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Print batch results</span></span><br><span class="line">            <span class="comment"># 这段蛮有教学意义的, tqdm怎么显示信息 </span></span><br><span class="line">            mloss = (mloss * i + loss_items) / (i + <span class="number">1</span>)  <span class="comment"># update mean losses</span></span><br><span class="line">            <span class="comment"># s = (&#x27;%8s%12s&#x27; + &#x27;%10.3g&#x27; * 7) % (&#x27;%g/%g&#x27; % (epoch, epochs - 1), &#x27;%g/%g&#x27; % (i, nb - 1), *mloss, len(targets), time.time() - t)</span></span><br><span class="line">            s = (<span class="string">&#x27;%8s%12s&#x27;</span> + <span class="string">&#x27;%10.3g&#x27;</span> * <span class="number">7</span>) % (</span><br><span class="line">                <span class="string">&#x27;%g/%g&#x27;</span> % (epoch, epochs - <span class="number">1</span>), <span class="string">&#x27;%g/%g&#x27;</span> % (i, nb - <span class="number">1</span>), *mloss, <span class="built_in">len</span>(targets), img_size)</span><br><span class="line">            t = time.time()</span><br><span class="line">            pbar.set_description(s)  <span class="comment"># print(s)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Report time</span></span><br><span class="line">        <span class="comment"># dt = (time.time() - t0) / 3600</span></span><br><span class="line">        <span class="comment"># print(&#x27;%g epochs completed in %.3f hours.&#x27; % (epoch - start_epoch + 1, dt))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Calculate mAP (always test final epoch, skip first 5 if opt.nosave)</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> (opt.notest <span class="keyword">or</span> (opt.nosave <span class="keyword">and</span> epoch &lt; <span class="number">10</span>)) <span class="keyword">or</span> epoch == epochs - <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">                <span class="comment"># 这里用到了作者额外写的一个类 test.py 用于getmAP和loss after each epoch</span></span><br><span class="line">                results, maps = test.test(cfg, data_cfg, batch_size=batch_size, img_size=opt.img_size, model=model,</span><br><span class="line">                                          conf_thres=<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Write epoch results</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;results.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">            file.write(s + <span class="string">&#x27;%11.3g&#x27;</span> * <span class="number">5</span> % results + <span class="string">&#x27;\n&#x27;</span>)  <span class="comment"># P, R, mAP, F1, test_loss</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Update best map</span></span><br><span class="line">        fitness = results[<span class="number">2</span>]</span><br><span class="line">        <span class="keyword">if</span> fitness &gt; best_fitness:</span><br><span class="line">            best_fitness = fitness</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Save training results</span></span><br><span class="line">        <span class="comment"># 保存训练结果和checkpoint</span></span><br><span class="line">        save = (<span class="keyword">not</span> opt.nosave) <span class="keyword">or</span> ((<span class="keyword">not</span> opt.evolve) <span class="keyword">and</span> (epoch == epochs - <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">if</span> save:</span><br><span class="line">            <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;results.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">                <span class="comment"># Create checkpoint</span></span><br><span class="line">                chkpt = &#123;<span class="string">&#x27;epoch&#x27;</span>: epoch,</span><br><span class="line">                         <span class="string">&#x27;best_fitness&#x27;</span>: best_fitness,</span><br><span class="line">                         <span class="string">&#x27;training_results&#x27;</span>: file.read(),</span><br><span class="line">                         <span class="string">&#x27;model&#x27;</span>: model.module.state_dict() <span class="keyword">if</span> <span class="built_in">type</span>(</span><br><span class="line">                             model) <span class="keyword">is</span> nn.parallel.DistributedDataParallel <span class="keyword">else</span> model.state_dict(),</span><br><span class="line">                         <span class="string">&#x27;optimizer&#x27;</span>: optimizer.state_dict()&#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save last checkpoint</span></span><br><span class="line">            torch.save(chkpt, last)</span><br><span class="line">            <span class="keyword">if</span> opt.bucket:</span><br><span class="line">                os.system(<span class="string">&#x27;gsutil cp %s gs://%s&#x27;</span> % (last, opt.bucket))  <span class="comment"># upload to bucket</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save best checkpoint</span></span><br><span class="line">            <span class="comment"># mAP是评价检测性能的极佳指标，best_fitness用来记录当前最好的检测性能。best_fitness初始化为0.0</span></span><br><span class="line">            <span class="keyword">if</span> best_fitness == fitness:</span><br><span class="line">                torch.save(chkpt, best)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Save backup every 10 epochs (optional)</span></span><br><span class="line">            <span class="comment"># 保存中间结果</span></span><br><span class="line">            <span class="keyword">if</span> epoch &gt; <span class="number">0</span> <span class="keyword">and</span> epoch % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                torch.save(chkpt, weights + <span class="string">&#x27;backup%g.pt&#x27;</span> % epoch)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Delete checkpoint</span></span><br><span class="line">            <span class="keyword">del</span> chkpt</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> results</span><br></pre></td></tr></table></figure>
<p>上文的重点梳理。</p>
<ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_40231500/article/details/89395617">torch.load(map_location=)</a>, cpu与gpu load时相互转化</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/u014380165/article/details/79119664">model.load_state_dict(strict=)</a>, strict默认是True，表示预训练模型的层和自己定义的网络结构层严格对应相等（比如层名和维度）</li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/idwtwt/article/details/82195000">model.parameters()</a>，看源码可以发现本质上来源于named_parameters()，后者是(name, param)，前者只有param</li>
<li>requires_grad, 是否进行梯度更新</li>
</ol>
<p><strong>补充知识</strong></p>
<ol>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/lscelory/article/details/81482586">加载预训练模型的权重</a><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">resnet152 = models.resnet152(pretrained=<span class="literal">True</span>) </span><br><span class="line">pretrained_dict = resnet152.state_dict() </span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">加载torchvision中的预训练模型和参数后通过state_dict()方法提取参数    </span></span><br><span class="line"><span class="string">也可以直接从官方model_zoo下载：    </span></span><br><span class="line"><span class="string">pretrained_dict = model_zoo.load_url(model_urls[&#x27;resnet152&#x27;])&quot;&quot;&quot;</span> </span><br><span class="line">model_dict = model.state_dict() </span><br><span class="line"><span class="comment"># 将pretrained_dict里不属于model_dict的键剔除掉 </span></span><br><span class="line">pretrained_dict = &#123;k: v <span class="keyword">for</span> k, v <span class="keyword">in</span> pretrained_dict.items() <span class="keyword">if</span> k <span class="keyword">in</span> model_dict&#125; </span><br><span class="line"><span class="comment"># 更新现有的model_dict </span></span><br><span class="line">model_dict.update(pretrained_dict) </span><br><span class="line"><span class="comment"># 加载我们真正需要的state_dict </span></span><br><span class="line">model.load_state_dict(model_dict)</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>&nbsp;<br>下面的暂时没看，没我需要的重点</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_mutation</span>(<span class="params">hyp, results</span>):</span></span><br><span class="line">    <span class="comment"># Write mutation results</span></span><br><span class="line">    a = <span class="string">&#x27;%11s&#x27;</span> * <span class="built_in">len</span>(hyp) % <span class="built_in">tuple</span>(hyp.keys())  <span class="comment"># hyperparam keys</span></span><br><span class="line">    b = <span class="string">&#x27;%11.4g&#x27;</span> * <span class="built_in">len</span>(hyp) % <span class="built_in">tuple</span>(hyp.values())  <span class="comment"># hyperparam values</span></span><br><span class="line">    c = <span class="string">&#x27;%11.3g&#x27;</span> * <span class="built_in">len</span>(results) % results  <span class="comment"># results (P, R, mAP, F1, test_loss)</span></span><br><span class="line">    print(<span class="string">&#x27;\n%s\n%s\nEvolved fitness: %s\n&#x27;</span> % (a, b, c))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> opt.bucket:</span><br><span class="line">        os.system(<span class="string">&#x27;gsutil cp gs://%s/evolve.txt .&#x27;</span> % opt.bucket)  <span class="comment"># download evolve.txt</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;evolve.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:  <span class="comment"># append result</span></span><br><span class="line">            f.write(c + b + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">        os.system(<span class="string">&#x27;gsutil cp evolve.txt gs://%s&#x27;</span> % opt.bucket)  <span class="comment"># upload evolve.txt</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;evolve.txt&#x27;</span>, <span class="string">&#x27;a&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(c + b + <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">100</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of epochs&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">16</span>, <span class="built_in">help</span>=<span class="string">&#x27;batch size&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--accumulate&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of batches to accumulate before optimizing&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--cfg&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;cfg/yolov3-spp.cfg&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;cfg file path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--data-cfg&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;data/coco_64img.data&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;coco.data file path&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--multi-scale&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;train at (1/1.5)x - 1.5x sizes&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--img-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">416</span>, <span class="built_in">help</span>=<span class="string">&#x27;inference size (pixels)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--rect&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;rectangular training&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--resume&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;resume training flag&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--transfer&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;transfer learning flag&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--num-workers&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">4</span>, <span class="built_in">help</span>=<span class="string">&#x27;number of Pytorch DataLoader workers&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--nosave&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;only save final checkpoint&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--notest&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;only test final epoch&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--xywh&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;use xywh loss instead of GIoU loss&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--evolve&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;evolve hyperparameters&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--bucket&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, default=<span class="string">&#x27;&#x27;</span>, <span class="built_in">help</span>=<span class="string">&#x27;gsutil bucket&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--var&#x27;</span>, default=<span class="number">0</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, <span class="built_in">help</span>=<span class="string">&#x27;debug variable&#x27;</span>)</span><br><span class="line">    opt = parser.parse_args()</span><br><span class="line">    print(opt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> opt.evolve:</span><br><span class="line">        opt.notest = <span class="literal">True</span>  <span class="comment"># only test final epoch</span></span><br><span class="line">        opt.nosave = <span class="literal">True</span>  <span class="comment"># only save final checkpoint</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Train</span></span><br><span class="line">    results = train(opt.cfg,</span><br><span class="line">                    opt.data_cfg,</span><br><span class="line">                    img_size=opt.img_size,</span><br><span class="line">                    epochs=opt.epochs,</span><br><span class="line">                    batch_size=opt.batch_size,</span><br><span class="line">                    accumulate=opt.accumulate)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Evolve hyperparameters (optional)</span></span><br><span class="line">    <span class="keyword">if</span> opt.evolve:</span><br><span class="line">        gen = <span class="number">1000</span>  <span class="comment"># generations to evolve</span></span><br><span class="line">        print_mutation(hyp, results)  <span class="comment"># Write mutation results</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(gen):</span><br><span class="line">            <span class="comment"># Get best hyperparameters</span></span><br><span class="line">            x = np.loadtxt(<span class="string">&#x27;evolve.txt&#x27;</span>, ndmin=<span class="number">2</span>)</span><br><span class="line">            fitness = x[:, <span class="number">2</span>] * <span class="number">0.5</span> + x[:, <span class="number">3</span>] * <span class="number">0.5</span>  <span class="comment"># fitness as weighted combination of mAP and F1</span></span><br><span class="line">            x = x[fitness.argmax()]  <span class="comment"># select best fitness hyps</span></span><br><span class="line">            <span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(hyp.keys()):</span><br><span class="line">                hyp[k] = x[i + <span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Mutate</span></span><br><span class="line">            init_seeds(seed=<span class="built_in">int</span>(time.time()))</span><br><span class="line">            s = [<span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.15</span>, <span class="number">.00</span>, <span class="number">.05</span>, <span class="number">.10</span>]  <span class="comment"># fractional sigmas</span></span><br><span class="line">            <span class="keyword">for</span> i, k <span class="keyword">in</span> <span class="built_in">enumerate</span>(hyp.keys()):</span><br><span class="line">                x = (np.random.randn(<span class="number">1</span>) * s[i] + <span class="number">1</span>) ** <span class="number">2.0</span>  <span class="comment"># plt.hist(x.ravel(), 300)</span></span><br><span class="line">                hyp[k] *= <span class="built_in">float</span>(x)  <span class="comment"># vary by 20% 1sigma</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># Clip to limits</span></span><br><span class="line">            keys = [<span class="string">&#x27;lr0&#x27;</span>, <span class="string">&#x27;iou_t&#x27;</span>, <span class="string">&#x27;momentum&#x27;</span>, <span class="string">&#x27;weight_decay&#x27;</span>]</span><br><span class="line">            limits = [(<span class="number">1e-4</span>, <span class="number">1e-2</span>), (<span class="number">0.00</span>, <span class="number">0.70</span>), (<span class="number">0.60</span>, <span class="number">0.95</span>), (<span class="number">0</span>, <span class="number">0.01</span>)]</span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> <span class="built_in">zip</span>(keys, limits):</span><br><span class="line">                hyp[k] = np.clip(hyp[k], v[<span class="number">0</span>], v[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Train mutation</span></span><br><span class="line">            results = train(opt.cfg,</span><br><span class="line">                            opt.data_cfg,</span><br><span class="line">                            img_size=opt.img_size,</span><br><span class="line">                            epochs=opt.epochs,</span><br><span class="line">                            batch_size=opt.batch_size,</span><br><span class="line">                            accumulate=opt.accumulate)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Write mutation results</span></span><br><span class="line">            print_mutation(hyp, results)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># # Plot results</span></span><br><span class="line">            <span class="comment"># import numpy as np</span></span><br><span class="line">            <span class="comment"># import matplotlib.pyplot as plt</span></span><br><span class="line">            <span class="comment"># a = np.loadtxt(&#x27;evolve_1000val.txt&#x27;)</span></span><br><span class="line">            <span class="comment"># x = a[:, 2] * a[:, 3]  # metric = mAP * F1</span></span><br><span class="line">            <span class="comment"># weights = (x - x.min()) ** 2</span></span><br><span class="line">            <span class="comment"># fig = plt.figure(figsize=(14, 7))</span></span><br><span class="line">            <span class="comment"># for i in range(len(hyp)):</span></span><br><span class="line">            <span class="comment">#     y = a[:, i + 5]</span></span><br><span class="line">            <span class="comment">#     mu = (y * weights).sum() / weights.sum()</span></span><br><span class="line">            <span class="comment">#     plt.subplot(2, 5, i+1)</span></span><br><span class="line">            <span class="comment">#     plt.plot(x.max(), mu, &#x27;o&#x27;)</span></span><br><span class="line">            <span class="comment">#     plt.plot(x, y, &#x27;.&#x27;)</span></span><br><span class="line">            <span class="comment">#     print(list(hyp.keys())[i],&#x27;%.4g&#x27; % mu)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
        </div>
        
<blockquote class="copyright">
    <p><strong>Link to this article : </strong><a class="permalink" href="http://yoursite.com/2020/02/04/deep_learning/yolo/yolov3%E4%BB%A3%E7%A0%81%E6%8E%A2%E7%A9%B6-3%20train.py/">http://yoursite.com/2020/02/04/deep_learning/yolo/yolov3代码探究-3 train.py/</a></p>
    <p><strong>This article is available under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)</a> License</strong></p>
</blockquote>


    </article>
    
    <section id="comments">
        
    </section>


    

</main>


<aside style="" id="sidebar" class="aside aside-fixture">
    <div class="toc-sidebar">
        <nav id="toc" class="article-toc">
            <h3 class="toc-title">Catalogue</h3>
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#yolov3%E4%BB%A3%E7%A0%81%E6%8E%A2%E7%A9%B6-3-train-py"><span class="toc-number">1.</span> <span class="toc-text">yolov3代码探究-3 train.py</span></a></li></ol>
        </nav>
    </div>
</aside>





        </section>
        <footer class="hidden lg:block fixed bottom-0 left-0 sm:w-1/12 lg:w-1/6 bg-gray-100 z-40">
    
    <div class="footer-social-links">
        
            <a target="_blank" rel="noopener" href="https://github.com/grac-gu">
                <i class="iconfont icon-github"></i>
            </a>
        
            <a href="/None">
                <i class="iconfont icon-telegram"></i>
            </a>
        
            <a href="/None">
                <i class="iconfont icon-twitter"></i>
            </a>
        
            <a href="/atom.xml">
                <i class="iconfont icon-rss"></i>
            </a>
        
    </div>
    
    
</footer>

        <div id="mask" class="hidden mask fixed inset-0 bg-gray-900 opacity-75 z-40"></div>
        <div id="search-view-container" class="hidden shadow-xl"></div>
        
<script src="/js/dom-event.min.js"></script>

<script src="//cdn.jsdelivr.net/npm/yox@1.0.0-alpha.121/dist/standard/prod/yox.min.js"></script>


<script src="/js/search.min.js"></script>



    <script src="//cdn.jsdelivr.net/npm/lightgallery.js@1.1.3/dist/js/lightgallery.min.js"></script>
    
<script src="/js/light-gallery.min.js"></script>





    </body>
</html>
